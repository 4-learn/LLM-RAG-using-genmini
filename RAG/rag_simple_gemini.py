import os
import numpy as np
from dotenv import load_dotenv
import google.generativeai as genai

# === åˆå§‹åŒ– ===
load_dotenv()
genai.configure(api_key=os.getenv("GEMINI_API_KEY"))

# === è®€å…¥ FAQ æ–‡ä»¶ ===
docs = []
with open("faq.txt", "r", encoding="utf-8") as f:
    chunks = f.read().strip().split("\n\n")
    for chunk in chunks:
        docs.append(chunk.strip())

# === æ–‡å­—è½‰å‘é‡ ===
def embed_text(text: str):
    """ä½¿ç”¨ Gemini çš„ embedding æ¨¡å‹å°‡æ–‡å­—è½‰æ›ç‚ºå‘é‡"""
    res = genai.embed_content(model="models/text-embedding-004", content=text)
    return np.array(res["embedding"])

embeddings = [embed_text(doc) for doc in docs]

# === ç›¸ä¼¼åº¦æœå°‹ (å« debug) ===
def search_similar(query, top_k=2):
    """ä»¥ cosine similarity æœå°‹æœ€ç›¸é—œçš„ FAQ æ®µè½ï¼ˆå« debug è¼¸å‡ºï¼‰"""
    print("\nğŸ” [DEBUG] å•é¡Œå…§å®¹ï¼š", query)

    # 1ï¸âƒ£ å–å¾— query çš„ embedding
    q_emb = embed_text(query)

    # 2ï¸âƒ£ è¨ˆç®—æ¯å€‹æ®µè½çš„ cosine similarity
    sims = []
    for idx, d_emb in enumerate(embeddings):
        sim = np.dot(q_emb, d_emb) / (np.linalg.norm(q_emb) * np.linalg.norm(d_emb))
        sims.append(sim)

    # 3ï¸âƒ£ æ’åºå¾Œå–å‰ k å
    sorted_idx = np.argsort(sims)[::-1]

    print("\nğŸ“Š [DEBUG] å„ FAQ ç›¸ä¼¼åº¦åˆ†æ•¸ï¼š")
    for i in sorted_idx:
        print(f"  ({i}) {sims[i]:.3f} â†’ {docs[i][:60]}")

    # 4ï¸âƒ£ å–å‰ k åçš„ç´¢å¼•
    best_idx = sorted_idx[:top_k]

    print("\nğŸ† [DEBUG] é¸ä¸­å‰ {} åï¼š".format(top_k))
    for rank, i in enumerate(best_idx, 1):
        print(f"  TOP {rank}: {sims[i]:.3f} â†’ {docs[i][:60]}")

    # 5ï¸âƒ£ å›å‚³é¸ä¸­çš„æ®µè½
    return [docs[i] for i in best_idx]


# === å•é¡Œ ===
question = input("è«‹è¼¸å…¥å•é¡Œï¼š")
context_list = search_similar(question)
context = "\n".join(f"[è³‡æ–™ä¾†æº{i+1}]\n{c}" for i, c in enumerate(context_list))

# === å¼·åŒ– Prompt ===
prompt = f"""
ä½ æ˜¯ä¸€å€‹å®¢æœåŠ©ç†ï¼Œå¿…é ˆæ ¹æ“šæˆ‘æä¾›çš„ FAQ å…§å®¹å›ç­”å•é¡Œã€‚
é€™äº› FAQ æ˜¯ç³»çµ±å·²ç¶“å¾çŸ¥è­˜åº«ä¸­æŸ¥å‡ºçš„æœ€ç›¸ä¼¼è³‡æ–™ä¾†æºã€‚
è«‹å‹™å¿…æ ¹æ“šå®ƒå€‘å›ç­”å•é¡Œï¼Œå³ä½¿å…§å®¹éƒ¨ä»½ç›¸é—œï¼Œä¹Ÿè¦æ ¹æ“šç¾æœ‰è³‡æ–™é€²è¡Œåˆç†æ¨æ–·ã€‚
ä¸è¦èªªã€Œæ‰¾ä¸åˆ°ã€æˆ–ã€ŒæœªæåŠã€ã€‚

å›ç­”æ™‚è«‹ç”¨ç¹é«”ä¸­æ–‡ã€‚

=== å·²æª¢ç´¢ FAQ å…§å®¹ ===
{context}

=== ä½¿ç”¨è€…å•é¡Œ ===
{question}
"""

# === å‘¼å« Gemini ===
model = genai.GenerativeModel("gemini-2.5-flash")
response = model.generate_content(prompt, generation_config={"temperature": 0.2})

print("\nğŸ¤– Gemini å›è¦†ï¼š", response.text)